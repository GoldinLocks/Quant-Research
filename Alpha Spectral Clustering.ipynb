{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline import Pipeline, CustomFilter, CustomFactor\n",
    "from quantopian.pipeline.data import Fundamentals \n",
    "from quantopian.pipeline.data import factset\n",
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline.classifiers.fundamentals import Sector  \n",
    "from quantopian.pipeline.classifiers.morningstar import Sector \n",
    "from quantopian.pipeline.filters import QTradableStocksUS, Q1500US, Q500US\n",
    "from quantopian.pipeline.filters.eventvestor import IsAnnouncedAcqTarget\n",
    "from quantopian.pipeline.data.psychsignal import stocktwits\n",
    "from quantopian.pipeline.data.psychsignal import aggregated_twitter_withretweets_stocktwits as st\n",
    "from quantopian.pipeline.data.zacks import EarningsSurprises\n",
    "from quantopian.pipeline.data import morningstar\n",
    "from quantopian.pipeline.factors import Latest\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.stats.mstats import winsorize\n",
    "from zipline.utils.numpy_utils import ( repeat_first_axis, repeat_last_axis )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.pipeline.factors import ( CustomFactor, BusinessDaysSincePreviousEvent, \n",
    "                                         BusinessDaysUntilNextEvent, SimpleMovingAverage, \n",
    "                                         AverageDollarVolume, Returns, RSI, \n",
    "                                         RollingLinearRegressionOfReturns, RollingSpearmanOfReturns, \n",
    "                                         AnnualizedVolatility, Returns, DailyReturns, EWMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphalens as al\n",
    "import pyfolio as pf\n",
    "from scipy import stats\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, OneClassSVM, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model, decomposition, ensemble, preprocessing, isotonic, metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LIMIT = 0.0\n",
    "N_FACTOR_WINDOW = 5 \n",
    "N_CLUSTERS = 5\n",
    "TAU = 5\n",
    "ALPHA_SMOOTH = 1-np.exp(-1.0/TAU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(a):\n",
    "    \n",
    "    a = np.nan_to_num(a - np.nanmean(a))\n",
    "    \n",
    "    a = winsorize(a, limits=[WIN_LIMIT,WIN_LIMIT])\n",
    "\n",
    "    return preprocessing.scale(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \n",
    "    r = x - x.mean()\n",
    "    denom = r.abs().sum()\n",
    "    \n",
    "    return r/denom  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _slope(ts):\n",
    "    x = np.arange(len(ts))  \n",
    "    log_ts = np.log(ts)  \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts)  \n",
    "    annualized_slope = (np.power(np.exp(slope), 250) - 1) \n",
    "    return annualized_slope * (r_value ** 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MORNINGSTAR_SECTOR_CODES = {\n",
    "     -1: 'Misc',\n",
    "    101: 'Basic Materials',\n",
    "    102: 'Consumer Cyclical',\n",
    "    103: 'Financial Services',\n",
    "    104: 'Real Estate',\n",
    "    205: 'Consumer Defensive',\n",
    "    206: 'Healthcare',\n",
    "    207: 'Utilities',\n",
    "    308: 'Communication Services',\n",
    "    309: 'Energy',\n",
    "    310: 'Industrials',\n",
    "    311: 'Technology' ,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = morningstar.balance_sheet\n",
    "cfs = morningstar.cash_flow_statement\n",
    "is_ = morningstar.income_statement\n",
    "or_ = morningstar.operation_ratios\n",
    "er = morningstar.earnings_report\n",
    "v = morningstar.valuation\n",
    "vr = morningstar.valuation_ratios\n",
    "es = EarningsSurprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_data = (factset.Fundamentals.capex_assets_qf.latest.notnull()\n",
    "            & factset.Fundamentals.zscore_qf.latest.notnull()\n",
    "            & factset.Fundamentals.assets.latest.notnull()\n",
    "            & Fundamentals.long_term_debt.latest.notnull()\n",
    "            & Fundamentals.current_debt.latest.notnull()\n",
    "            & Fundamentals.cash_and_cash_equivalents.latest.notnull()\n",
    "            & Fundamentals.growth_score.latest.notnull()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap = Fundamentals.market_cap.latest > 1e8 # Market_Cap over 100mil\n",
    "is_liquid = AverageDollarVolume(window_length=21).percentile_between(90, 100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_tradeable = (QTradableStocksUS()\n",
    "                & is_liquid\n",
    "                & has_data\n",
    "                & market_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_factors():\n",
    "    \n",
    "    class MessageSum(CustomFactor):\n",
    "        inputs = [USEquityPricing.high, USEquityPricing.low, USEquityPricing.close, stocktwits.bull_scored_messages, stocktwits.bear_scored_messages, stocktwits.total_scanned_messages]\n",
    "        window_length = 21\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, high, low, close, bull, bear, total):\n",
    "            v = np.nansum((high-low)/close, axis=0)\n",
    "            out[:] = preprocess(v*np.nansum(total*(bear-bull), axis=0))\n",
    "                \n",
    "    class fcf(CustomFactor):\n",
    "        inputs = [Fundamentals.fcf_yield]\n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, fcf_yield):\n",
    "            out[:] = preprocess(np.nan_to_num(fcf_yield[-1,:]))\n",
    "                \n",
    "    class mean_rev(CustomFactor):   \n",
    "        inputs = [USEquityPricing.high,USEquityPricing.low,USEquityPricing.close]\n",
    "        window_length = 30\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, high, low, close):\n",
    "            \n",
    "            p = (high+low+close)/3\n",
    " \n",
    "            m = len(close[0,:])\n",
    "            n = len(close[:,0])\n",
    "                \n",
    "            b = np.zeros(m)\n",
    "            a = np.zeros(m)\n",
    "                \n",
    "            for k in range(10,n+1):\n",
    "                price_rel = np.nanmean(p[-k:,:],axis=0)/p[-1,:]\n",
    "                wt = np.nansum(price_rel)\n",
    "                b += wt*price_rel\n",
    "                price_rel = 1.0/price_rel\n",
    "                wt = np.nansum(price_rel)\n",
    "                a += wt*price_rel\n",
    "                \n",
    "            out[:] = preprocess(b-a)\n",
    "                \n",
    "    class volatility(CustomFactor):\n",
    "        inputs = [USEquityPricing.high, USEquityPricing.low, USEquityPricing.close, USEquityPricing.volume]\n",
    "        window_length = 5\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, high, low, close, volume):\n",
    "            vol = np.nansum(volume,axis=0)*np.nansum(np.absolute((high-low)/close),axis=0)\n",
    "            out[:] = preprocess(-vol)\n",
    "                \n",
    "    class growthscore(CustomFactor):\n",
    "        inputs = [Fundamentals.growth_score]\n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, growth_score):\n",
    "            out[:] = preprocess(growth_score[-1,:])\n",
    "                \n",
    "    class MoneyflowVolume5d(CustomFactor):\n",
    "        inputs = (USEquityPricing.close, USEquityPricing.volume)\n",
    "        window_length = 6\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, close_extra, volume_extra):\n",
    "            close = close_extra[1:]\n",
    "            volume = volume_extra[1:]\n",
    "                \n",
    "            dollar_volume = close * volume\n",
    "            denominator = dollar_volume.sum(axis=0)\n",
    "                \n",
    "            difference = np.diff(close_extra, axis=0)\n",
    "            direction = np.where(difference > 0, 1, -1)\n",
    "            numerator = (direction * dollar_volume).sum(axis=0)\n",
    "                \n",
    "            out[:] = preprocess(-np.divide(numerator, denominator))\n",
    "                \n",
    "    class Trendline(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        _x = np.arange(window_length)\n",
    "        _x_var = np.var(_x)\n",
    " \n",
    "        def compute(self, today, assets, out, close):\n",
    "            \n",
    "            x_matrix = repeat_last_axis(\n",
    "            (self.window_length - 1) / 2 - self._x,\n",
    "            len(assets),\n",
    "            )\n",
    " \n",
    "            y_bar = np.nanmean(close, axis=0)\n",
    "            y_bars = repeat_first_axis(y_bar, self.window_length)\n",
    "            y_matrix = close - y_bars\n",
    " \n",
    "            out[:] = preprocess(-np.divide(\n",
    "            (x_matrix * y_matrix).sum(axis=0) / self._x_var,\n",
    "            self.window_length\n",
    "            ))\n",
    "                \n",
    "    class SalesGrowth(CustomFactor):\n",
    "        inputs = [factset.Fundamentals.sales_gr_qf]\n",
    "        window_length = 2*252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, sales_growth):\n",
    "            sales_growth = np.nan_to_num(sales_growth)\n",
    "            sales_growth = preprocessing.scale(sales_growth,axis=0)\n",
    "            out[:] = preprocess(sales_growth[-1])\n",
    " \n",
    "    class GrossMarginChange(CustomFactor):\n",
    "        window_length = 2*252\n",
    "        inputs = [factset.Fundamentals.ebit_oper_mgn_qf]\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, ebit_oper_mgn):\n",
    "            ebit_oper_mgn = np.nan_to_num(ebit_oper_mgn)\n",
    "            ebit_oper_mgn = preprocessing.scale(ebit_oper_mgn,axis=0)\n",
    "            out[:] = preprocess(ebit_oper_mgn[-1])\n",
    " \n",
    "    class Gross_Income_Margin(CustomFactor):\n",
    "        inputs = [Fundamentals.cost_of_revenue, Fundamentals.total_revenue]\n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, cost_of_revenue, sales):\n",
    "            gross_income_margin = sales[-1]/sales[-1] - cost_of_revenue[-1]/sales[-1]\n",
    "            out[:] = preprocess(-gross_income_margin)\n",
    "        \n",
    "    class CapEx_Vol(CustomFactor):\n",
    "        inputs=[\n",
    "            factset.Fundamentals.capex_assets_qf]\n",
    "        window_length = 2*252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, capex_assets):\n",
    "                 \n",
    "            out[:] = preprocess(-np.ptp(capex_assets,axis=0))\n",
    "                \n",
    "    class fcf_ev(CustomFactor):\n",
    "        inputs=[\n",
    "            Fundamentals.fcf_per_share,\n",
    "            Fundamentals.shares_outstanding,\n",
    "            Fundamentals.enterprise_value,]\n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, fcf, shares, ev):\n",
    "            v = fcf*shares/ev\n",
    "            v[np.isinf(v)] = np.nan\n",
    "                 \n",
    "            out[:] = preprocess(v[-1])\n",
    "                               \n",
    "    class TEM(CustomFactor):\n",
    "        inputs=[factset.Fundamentals.capex_qf_asof_date,\n",
    "            factset.Fundamentals.capex_qf,\n",
    "            factset.Fundamentals.assets]\n",
    "        window_length = 390\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, asof_date, capex, total_assets):\n",
    "            values = capex/total_assets\n",
    "            values[np.isinf(values)] = np.nan\n",
    "            out_temp = np.zeros_like(values[-1,:])\n",
    "            for column_ix in range(asof_date.shape[1]):\n",
    "                _, unique_indices = np.unique(asof_date[:, column_ix], return_index=True)\n",
    "                quarterly_values = values[unique_indices, column_ix]\n",
    "                if len(quarterly_values) < 6:\n",
    "                    quarterly_values = np.hstack([\n",
    "                    np.repeat([np.nan], 6 - len(quarterly_values)),\n",
    "                    quarterly_values,\n",
    "                    ])\n",
    "            \n",
    "                out_temp[column_ix] = np.std(quarterly_values[-6:])\n",
    "                \n",
    "            out[:] = preprocess(-out_temp)\n",
    "                \n",
    "    class Piotroski(CustomFactor):\n",
    "        inputs = [\n",
    "                Fundamentals.roa,\n",
    "                Fundamentals.operating_cash_flow,\n",
    "                Fundamentals.cash_flow_from_continuing_operating_activities,\n",
    "                Fundamentals.long_term_debt_equity_ratio,\n",
    "                Fundamentals.current_ratio,\n",
    "                Fundamentals.shares_outstanding,\n",
    "                Fundamentals.gross_margin,\n",
    "                Fundamentals.assets_turnover,\n",
    "                ]\n",
    " \n",
    "        window_length = 100\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out,roa, cash_flow, cash_flow_from_ops, long_term_debt_ratio, current_ratio, shares_outstanding, gross_margin, assets_turnover):\n",
    "            \n",
    "            profit = (\n",
    "                        (roa[-1] > 0).astype(int) +\n",
    "                        (cash_flow[-1] > 0).astype(int) +\n",
    "                        (roa[-1] > roa[0]).astype(int) +\n",
    "                        (cash_flow_from_ops[-1] > roa[-1]).astype(int)\n",
    "                    )\n",
    "        \n",
    "            leverage = (\n",
    "                        (long_term_debt_ratio[-1] < long_term_debt_ratio[0]).astype(int) +\n",
    "                        (current_ratio[-1] > current_ratio[0]).astype(int) + \n",
    "                        (shares_outstanding[-1] <= shares_outstanding[0]).astype(int)\n",
    "                        )\n",
    "        \n",
    "            operating = (\n",
    "                        (gross_margin[-1] > gross_margin[0]).astype(int) +\n",
    "                        (assets_turnover[-1] > assets_turnover[0]).astype(int)\n",
    "                        )\n",
    "        \n",
    "            out[:] = preprocess(profit + leverage + operating)\n",
    "            \n",
    "    class Altman_Z(CustomFactor):\n",
    "        inputs=[factset.Fundamentals.zscore_qf]\n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, zscore_qf):\n",
    "            out[:] = preprocess(zscore_qf[-1])\n",
    "            \n",
    "    class HurstExp(CustomFactor):  \n",
    "        inputs = [USEquityPricing.close]  \n",
    "        window_length = int(252*0.5)\n",
    "        window_safe = True\n",
    "        def Hurst(self, ts):   #Fast\n",
    "            lags=np.arange(2,20)  \n",
    "            tau = [np.sqrt(np.std(np.subtract(ts[lag:], ts[:-lag]))) for lag in lags]        \n",
    "            n = len(lags)  \n",
    "            x = np.log(lags)  \n",
    "            y = np.log(tau)  \n",
    "            poly = (n*(x*y).sum() - x.sum()*y.sum()) / (n*(x*x).sum() - x.sum()*x.sum())\n",
    "            hurst_exp = poly*2.0\n",
    "            return hurst_exp\n",
    "        def compute(self, today, assets, out,  CLOSE):\n",
    "            SERIES = np.log(np.nan_to_num(CLOSE)) \n",
    "            hurst_exp_per_asset = map(self.Hurst, [SERIES[:,col_id].flatten() for col_id in np.arange(SERIES.shape[1])])  \n",
    "            h = np.nan_to_num(hurst_exp_per_asset)\n",
    "            out[:] = preprocess(-h)\n",
    "            \n",
    "    class ClenowMomentum(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 90\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, close):\n",
    "            res = []\n",
    "            for i in range(close.shape[1]):\n",
    "                res.append(_slope(close[:, i]))\n",
    "            out[:] = preprocess(res)\n",
    "            \n",
    "    class ItoA(CustomFactor):\n",
    "        inputs = [factset.Fundamentals.ppe_gross,\n",
    "              factset.Fundamentals.inven,\n",
    "              factset.Fundamentals.assets]\n",
    "        window_length = 270\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, ppe, inv, ta):\n",
    "            ppe = np.nan_to_num(ppe)\n",
    "            inv = np.nan_to_num(inv)\n",
    "            out[:] = preprocess(-(ppe[-1]-ppe[0]+inv[-1]-inv[0])/ta[0])\n",
    "            \n",
    "    factors = [\n",
    "            MessageSum,\n",
    "            ItoA,\n",
    "            HurstExp,\n",
    "            ClenowMomentum,\n",
    "            fcf,\n",
    "            mean_rev,\n",
    "            volatility,\n",
    "            growthscore,\n",
    "            MoneyflowVolume5d,\n",
    "            Trendline,\n",
    "            SalesGrowth,\n",
    "            GrossMarginChange,\n",
    "            Gross_Income_Margin,\n",
    "            CapEx_Vol,\n",
    "            fcf_ev,\n",
    "            TEM,\n",
    "            Piotroski,\n",
    "            Altman_Z,  \n",
    "        ]\n",
    "    \n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factor_N_Days_Ago(CustomFactor):\n",
    "    def compute(self, today, assets, out, input_factor):\n",
    "        out[:] = input_factor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_pipeline():\n",
    "    \n",
    "    universe = QTradableStocksUS()\n",
    "    \n",
    "    factors = make_factors()\n",
    "    \n",
    "    pipeline_columns = {}\n",
    "    for k,f in enumerate(factors):\n",
    "        for days_ago in range(N_FACTOR_WINDOW):\n",
    "            pipeline_columns['alpha1_'+str(k)+'_'+str(days_ago)] = Factor_N_Days_Ago([f(mask=universe)], window_length=days_ago+1, mask=universe)\n",
    "    \n",
    "    pipe = Pipeline(columns = pipeline_columns,\n",
    "    screen = universe)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:169: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/arraysetops.py:200: FutureWarning: In the future, NAT != NAT will be True rather than False.\n",
      "  flag = np.concatenate(([True], aux[1:] != aux[:-1]))\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:153: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "start_timer = time()\n",
    "start = pd.Timestamp(\"2010-03-01\") \n",
    "end = pd.Timestamp(\"2014-03-01\")\n",
    "data_1 = run_pipeline(factor_pipeline(), start_date=start, end_date=end,chunksize=252)\n",
    "end_timer = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Time to run pipeline %.2f secs\" % (end_timer - start_timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_list = data_1.index.levels[1]\n",
    "num_stocks = len(asset_list)\n",
    "data_1.dropna(inplace=True)\n",
    "print 'Number of stocks:', num_stocks\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_factors():\n",
    "                \n",
    "    class Quick_Ratio(CustomFactor):\n",
    "        inputs=[factset.Fundamentals.quick_ratio_qf]\n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, quick_ratio_qf):\n",
    "            out[:] = preprocess(quick_ratio_qf[-1])\n",
    "                \n",
    "    class AdvancedMomentum(CustomFactor):\n",
    "        inputs = (USEquityPricing.close, Returns(window_length=126))\n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, prices, returns):\n",
    "            am = np.divide(\n",
    "            (\n",
    "            (prices[-21] - prices[-252]) / prices[-252] -\n",
    "            prices[-1] - prices[-21]\n",
    "            ) / prices[-21],\n",
    "            np.nanstd(returns, axis=0)\n",
    "            )\n",
    "                \n",
    "            out[:] = preprocess(-am)\n",
    "            \n",
    "    class ROA(CustomFactor):  \n",
    "        inputs = [Fundamentals.roa]  \n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, roa):  \n",
    "            out[:] = preprocess(np.where(roa[-1]>0,1,0))\n",
    "            \n",
    "    class FCFTA(CustomFactor):  \n",
    "        inputs = [Fundamentals.free_cash_flow,  \n",
    "                 Fundamentals.total_assets]  \n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, fcf, ta):  \n",
    "            out[:] = preprocess(np.where(fcf[-1]/ta[-1]>0,1,0))\n",
    "            \n",
    "    class ROA_GROWTH(CustomFactor):  \n",
    "        inputs = [Fundamentals.roa]  \n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, roa):  \n",
    "            out[:] = np.where(roa[-1]>roa[-252],1,0)\n",
    "            \n",
    "    class FCFTA_ROA(CustomFactor):  \n",
    "        inputs = [Fundamentals.free_cash_flow,  \n",
    "                  Fundamentals.total_assets,  \n",
    "                  Fundamentals.roa]  \n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, fcf, ta, roa):  \n",
    "            out[:] = preprocess(np.where(fcf[-1]/ta[-1]>roa[-1],1,0))\n",
    "            \n",
    "    class FCFTA_GROWTH(CustomFactor):  \n",
    "        inputs = [Fundamentals.free_cash_flow,  \n",
    "                  Fundamentals.total_assets]  \n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, fcf, ta):  \n",
    "            out[:] = preprocess(np.where(fcf[-1]/ta[-1]>fcf[-252]/ta[-252],1,0))\n",
    "            \n",
    "    class LTD_GROWTH(CustomFactor):  \n",
    "        inputs = [Fundamentals.total_assets,  \n",
    "                  Fundamentals.long_term_debt]  \n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, ta, ltd):  \n",
    "            out[:] = preprocess(np.where(ltd[-1]/ta[-1]<ltd[-252]/ta[-252],1,0))\n",
    "            \n",
    "    class CR_GROWTH(CustomFactor):  \n",
    "        inputs = [Fundamentals.current_ratio]  \n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, cr):  \n",
    "            out[:] = preprocess(np.where(cr[-1]>cr[-252],1,0))\n",
    "            \n",
    "    class GM_GROWTH(CustomFactor):  \n",
    "        inputs = [Fundamentals.gross_margin]  \n",
    "        window_length = 252  \n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, gm):  \n",
    "            out[:] = preprocess(np.where(gm[-1]>gm[-252],1,0))\n",
    "            \n",
    "    class ATR_GROWTH(CustomFactor):  \n",
    "        inputs = [Fundamentals.assets_turnover]  \n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, atr):  \n",
    "            out[:] = preprocess(np.where(atr[-1]>atr[-252],1,0))\n",
    "            \n",
    "    class NEQISS(CustomFactor):  \n",
    "        inputs = [Fundamentals.shares_outstanding]  \n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, so):  \n",
    "            out[:] = preprocess(np.where(so[-1]-so[-252]<1,1,0))\n",
    "            \n",
    "    class GM_GROWTH_2YR(CustomFactor):  \n",
    "        inputs = [Fundamentals.gross_margin]  \n",
    "        window_length = 504\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, gm):  \n",
    "            out[:] = preprocess(gmean([gm[-1]+1, gm[-252]+1,gm[-504]+1])-1) \n",
    "            \n",
    "    class ROA_GROWTH_2YR(CustomFactor):  \n",
    "        inputs = [Fundamentals.roa]  \n",
    "        window_length = 504\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, roa):  \n",
    "            out[:] = preprocess(gmean([roa[-1]+1, roa[-252]+1,roa[-504]+1])-1)\n",
    "            \n",
    "    class ROIC_GROWTH_2YR(CustomFactor):  \n",
    "        inputs = [Fundamentals.roic]  \n",
    "        window_length = 504\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, roic):  \n",
    "            out[:] = preprocess(gmean([roic[-1]+1, roic[-252]+1,roic[-504]+1])-1)\n",
    "            \n",
    "    class GM_GROWTH_8YR(CustomFactor):  \n",
    "        inputs = [Fundamentals.gross_margin]  \n",
    "        window_length = 8\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, gm):  \n",
    "            out[:] = preprocess(gmean([gm[-1]+1, gm[-2]+1, gm[-3]+1, gm[-4]+1, gm[-5]+1, gm[-6]+1, gm[-7]+1, gm[-8]+1])-1)         \n",
    "            \n",
    "    class ROA_GROWTH_8YR(CustomFactor):  \n",
    "        inputs = [Fundamentals.roa]  \n",
    "        window_length = 9\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, roa):  \n",
    "            out[:] = preprocess(gmean([roa[-1]/100+1, roa[-2]/100+1,roa[-3]/100+1,roa[-4]/100+1,roa[-5]/100+1,roa[-6]/100+1,roa[-7]/100+1,roa[-8]/100+1])-1) \n",
    "            \n",
    "    class ROIC_GROWTH_8YR(CustomFactor):  \n",
    "        inputs = [Fundamentals.roic]  \n",
    "        window_length = 9\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, roic):  \n",
    "            out[:] = preprocess(gmean([roic[-1]/100+1, roic[-2]/100+1,roic[-3]/100+1,roic[-4]/100+1,roic[-5]/100+1,roic[-6]/100+1,roic[-7]/100+1,roic[-8]/100+1])-1)              \n",
    "            \n",
    "    class Value(CustomFactor):\n",
    "        inputs = [cfs.operating_cash_flow, v.enterprise_value] \n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, ocf, ev):\n",
    "            factor_df = pd.DataFrame(index=assets)\n",
    "            factor_df[\"ocf\"] = ocf[-1]\n",
    "            factor_df[\"ev\"] = ev[-1]\n",
    "            out[:] = preprocess((factor_df['ocf'] / factor_df['ev']))\n",
    "            \n",
    "    class GP_to_A(CustomFactor):\n",
    "        inputs = [is_.gross_profit, bs.total_assets]\n",
    "        window_length = 1\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, gross_profit, total_assets):       \n",
    "            out[:] = preprocess(gross_profit[-1] / total_assets[-1])\n",
    "            \n",
    "    class efficiency_ratio(CustomFactor):    \n",
    "        inputs = [USEquityPricing.close, USEquityPricing.high, USEquityPricing.low]   \n",
    "        window_length = 126\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, close, high, low):\n",
    "            lb = self.window_length\n",
    "            e_r = np.zeros(len(assets), dtype=np.float64)\n",
    "            a=np.array([high[1:(lb):1]-low[1:(lb):1],\n",
    "                     abs(high[1:(lb):1]-close[0:(lb-1):1]),\n",
    "                     abs(low[1:(lb):1]-close[0:(lb-1):1])])      \n",
    "            b=a.T.max(axis=1)\n",
    "            c=b.sum(axis=1)\n",
    "            e_r=abs(close[-1]-close[0]) / c  \n",
    "            out[:] = preprocess(e_r)\n",
    "            \n",
    "    class Price_Oscillator(CustomFactor):\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "        window_safe = True\n",
    "        def compute(self, today, assets, out, close):\n",
    "            four_week_period = close[-20:]\n",
    "            out[:] = preprocess((np.nanmean(four_week_period, axis=0) /\n",
    "                      np.nanmean(close, axis=0)) - 1.)\n",
    "            \n",
    "    factors = [\n",
    "            Quick_Ratio,\n",
    "            Price_Oscillator,\n",
    "            efficiency_ratio,\n",
    "            GP_to_A,\n",
    "            Value,\n",
    "            AdvancedMomentum,\n",
    "            ROA,  \n",
    "            FCFTA,  \n",
    "            ROA_GROWTH,  \n",
    "            FCFTA_ROA,  \n",
    "            FCFTA_GROWTH,  \n",
    "            LTD_GROWTH,  \n",
    "            CR_GROWTH,  \n",
    "            GM_GROWTH,  \n",
    "            ATR_GROWTH,  \n",
    "            NEQISS,  \n",
    "            GM_GROWTH_2YR,  \n",
    "            ROA_GROWTH_2YR,  \n",
    "            ROIC_GROWTH_2YR,  \n",
    "            ROA_GROWTH_8YR,  \n",
    "            ROIC_GROWTH_8YR,  \n",
    "        ]\n",
    "    \n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_pipeline():\n",
    "    \n",
    "    universe = QTradableStocksUS()\n",
    "    \n",
    "    factors = make_factors()\n",
    "        \n",
    "    pipeline_columns = {}\n",
    "    for k,f in enumerate(factors):\n",
    "        for days_ago in range(N_FACTOR_WINDOW):\n",
    "            pipeline_columns['alpha2_'+str(k)+'_'+str(days_ago)] = Factor_N_Days_Ago([f(mask=universe)], window_length=days_ago+1, mask=universe)\n",
    "    \n",
    "    pipeline_columns['Sector'] = Sector()\n",
    "    \n",
    "    pipeline_columns['5D_Returns'] = Returns(inputs = [USEquityPricing.close],\n",
    "                                      mask = universe, window_length = 5)\n",
    "    \n",
    "    pipe = Pipeline(columns = pipeline_columns,\n",
    "    screen = universe)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timer = time()\n",
    "data_2 = run_pipeline(factor_pipeline(), start_date=start, end_date=end,chunksize=252)\n",
    "end_timer = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Time to run pipeline %.2f secs\" % (end_timer - start_timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20 = data_2.drop('Sector', axis=1)\n",
    "data_20 = data_20.drop('5D_Returns', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.concat([data_20, data_1], axis=1)\n",
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = df_a.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = len(alphas.columns)/N_FACTOR_WINDOW\n",
    "n_stocks = len(alphas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_flattened = np.zeros((n_factors,n_stocks*N_FACTOR_WINDOW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(n_factors):\n",
    "        a = alphas.iloc[:,f*N_FACTOR_WINDOW:(f+1)*N_FACTOR_WINDOW].values\n",
    "        alphas_flattened[f,:] = np.ravel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = SpectralClustering(n_clusters=N_CLUSTERS,assign_labels=\"discretize\",random_state=0).fit(alphas_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(n_factors)\n",
    "for k,w in enumerate(clustering.labels_):\n",
    "    weights[k] = Counter(clustering.labels_)[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_current = alphas.ix[:,::N_FACTOR_WINDOW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_alpha = pd.Series(np.zeros_like(alphas_current.iloc[:,1].values),index=alphas_current.index)\n",
    "for k in range(n_factors):\n",
    "    combined_alpha += alphas_current.iloc[:,k]/weights[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_alpha_bsc = combined_alpha\n",
    "combined_alpha_bsc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_alpha = normalize(combined_alpha)\n",
    "combined_alpha = (1-ALPHA_SMOOTH)*combined_alpha\n",
    "combined_alpha = combined_alpha.add(ALPHA_SMOOTH*combined_alpha,fill_value=0).dropna()\n",
    "combined_alpha = normalize(combined_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_alpha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame({'combined_alpha': combined_alpha,\n",
    "                         'combined_alphaz': combined_alpha_bsc})\n",
    "s_1 = data_2['Sector']\n",
    "alpha_df.loc[:, 'Sector'] = s_1\n",
    "s_2 = data_2['5D_Returns']\n",
    "alpha_df.loc[:, '5D_Returns'] = s_2\n",
    "alpha_df['Sector_Name'] = alpha_df['Sector'].map(MORNINGSTAR_SECTOR_CODES)\n",
    "alpha_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing = get_pricing(asset_list, start, end + pd.Timedelta(days=30), fields=\"close_price\")\n",
    "stock_rets = pricing.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df['CA_decile']=pd.qcut(alpha_df['combined_alpha'],10,labels=False)+1\n",
    "alpha_df['RET_decile']=pd.qcut(alpha_df['5D_Returns'],10,labels=False)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA=alpha_df.groupby('CA_decile')['5D_Returns'].apply(lambda x: x.mean())\n",
    "CA.plot(kind='bar', color='blue',  position=0, width=0.5,label='combined_alpha')\n",
    "plt.xlabel('Decile')\n",
    "plt.ylabel('Average 5D_Returns')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_averagesz = alpha_df.groupby('Sector_Name')['combined_alpha'].apply(lambda x: x.mean())\n",
    "sector_averagesz.plot(kind='bar', color='blue',  position=0, width=0.5,label='combined_alpha_z')\n",
    "plt.ylabel('Alpha Factor Return')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_averagesb = alpha_df.groupby('Sector_Name')['5D_Returns'].apply(lambda x: x.mean())\n",
    "plt.ylabel('5D_Returns')\n",
    "sector_averagesb.plot(kind='bar', color='red',  position=1, width=0.5,label='5D_Returns')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets0 = alpha_df['5D_Returns']\n",
    "alpha = alpha_df['combined_alpha']\n",
    "alphaz = alpha_df['combined_alphaz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alpha.describe().loc[['mean', 'std', 'min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(alpha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_s = stats.spearmanr(alpha, rets0)\n",
    "print 'Correlation Coefficient: ' + str(r_s[0])\n",
    "print 'p-value: ' + str(r_s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = alpha_df.drop('Sector_Name', axis=1)\n",
    "df1.index = df1.index.droplevel(1)\n",
    "df1.dropna()\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(rets0, prepend=False)\n",
    "ols = sm.OLS(alphaz, x).fit()\n",
    "beta = ols.params\n",
    "y_fit = [x.min().dot(beta), x.max().dot(beta)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = df1\n",
    "cm = plt.get_cmap('jet')\n",
    "colors = np.linspace(0.1, 1, len(alpha_df))\n",
    "sc = plt.scatter(rets0, alphaz, s=50, c=colors, cmap=cm, \n",
    "                 edgecolor='k', alpha=0.7, label='Price Data')\n",
    "plt.plot([x.min()[0], x.max()[0]], y_fit, 'black', linestyle='--', linewidth=1, label='OLS Fit')\n",
    "plt.legend()\n",
    "cb = plt.colorbar(sc)\n",
    "cb.ax.set_yticklabels([str(p.date()) for p in i[::len(i)//9].index])\n",
    "plt.xlabel('5D_Returns')\n",
    "plt.ylabel('combined_alpha');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.research.experimental import get_factor_returns, get_factor_loadings\n",
    "import empyrical as ep\n",
    "import pyfolio as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor1_data = al.utils.get_clean_factor_and_forward_returns(\n",
    "    factor=alpha_df[\"combined_alpha\"],\n",
    "    prices=pricing,\n",
    "    groupby=alpha_df[\"Sector\"],\n",
    "    quantiles=5,\n",
    "    periods=(1, 5, 10, 21)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_labels = dict(Sector.SECTOR_NAMES)\n",
    "sector_labels[-1] = \"Unknown\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_loadings = get_factor_loadings(asset_list, start, end)\n",
    "factor_returns = get_factor_returns(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ic_over_time(factor_data, label='', ax=None):\n",
    "    mic = al.performance.mean_information_coefficient(factor_data)\n",
    "    mic.index = mic.index.map(lambda x: int(x[:-1])) \n",
    "    ax = mic.plot(label=label, ax=ax)\n",
    "    ax.set(xlabel='Days', ylabel='Mean IC')\n",
    "    ax.legend()\n",
    "    ax.axhline(0, ls='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_specific_returns(total_returns, factor_returns=None, factor_loadings=None, assets=None):\n",
    "    if assets is not None:\n",
    "        factor_loadings = get_factor_loadings(assets, start, end + pd.Timedelta(days=30))\n",
    "        factor_returns = get_factor_returns(start, end + pd.Timedelta(days=30))\n",
    "    elif factor_loadings is None or factor_returns is None:\n",
    "        raise ValueError('Supply either assets or factor_returns and factor_loadings')\n",
    "    \n",
    "    factor_returns.index = factor_returns.index.set_names(['dt'])\n",
    "    factor_loadings.index = factor_loadings.index.set_names(['dt', 'ticker'])\n",
    "    common_returns = factor_loadings.mul(factor_returns).sum(axis='columns').unstack()\n",
    "    specific_returns = total_returns - common_returns\n",
    "    return specific_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_rets_specific = compute_specific_returns(stock_rets, factor_returns, factor_loadings)\n",
    "cr_specific = ep.cum_returns(stock_rets_specific, starting_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_specific1 = al.utils.get_clean_factor_and_forward_returns(\n",
    "    alpha_df[\"combined_alpha\"], \n",
    "    cr_specific,\n",
    "    periods=range(1, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_portfolio_returns(factor, pricing, equal_weight=True, delay=0):\n",
    "    if equal_weight:\n",
    "        factor = np.sign(factor)\n",
    "        bins = (-1, 0, 1)\n",
    "        quantiles = None\n",
    "        zero_aware = False\n",
    "    else:\n",
    "        bins = None\n",
    "        quantiles = 5\n",
    "        zero_aware = True\n",
    "        \n",
    "    pos = factor.unstack().fillna(0)\n",
    "    # Factor might not be daily, get trading index from pricing data and ffill\n",
    "    pos = (pos / (pos.abs().sum())).reindex(pricing.index).ffill().shift(delay)\n",
    "    # Fully invested, shorts show up as cash\n",
    "    pos['cash'] = pos[pos < 0].sum(axis='columns')\n",
    "    \n",
    "    factor_and_returns = al.utils.get_clean_factor_and_forward_returns(\n",
    "        pos.stack().loc[lambda x: x != 0], \n",
    "        pricing, periods=(1,), quantiles=quantiles, bins=bins, \n",
    "        zero_aware=zero_aware)\n",
    "    \n",
    "    return al.performance.factor_returns(factor_and_returns)['1D'], pos\n",
    "\n",
    "portfolio_returns, portfolio_pos = factor_portfolio_returns(alpha_df[\"combined_alpha\"], pricing, \n",
    "                                                             equal_weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_loadings.index = factor_loadings.index.set_names(['dt', 'ticker'])\n",
    "portfolio_pos.index = portfolio_pos.index.set_names(['dt'])\n",
    "risk_exposures_portfolio, perf_attribution = pf.perf_attrib.perf_attrib(\n",
    "    portfolio_returns, \n",
    "    portfolio_pos, \n",
    "    factor_returns, \n",
    "    factor_loadings, \n",
    "    pos_in_dollars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor1_returns, factor1_positions, factor1_benchmark = \\\n",
    "    al.performance.create_pyfolio_input(factor1_data,\n",
    "                                        period='5D',\n",
    "                                        capital=10000000,\n",
    "                                        long_short=True,\n",
    "                                        group_neutral=False,\n",
    "                                        equal_weight=True,\n",
    "                                        quantiles=[1,5],\n",
    "                                        groups=None,\n",
    "                                        benchmark_period='1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_list = factor1_data.index.levels[1].unique()\n",
    "start_date = factor1_data.index.levels[0].min()\n",
    "end_date   = factor1_data.index.levels[0].max()\n",
    "factor_loadings.index.names = ['dt', 'ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ic_over_time(factor1_data, label='combined_alpha_n_IC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ic_over_time(factor1_data, label='combined_alpha_n Total returns')\n",
    "plot_ic_over_time(factor_data_specific1, label='combined_alpha_n Specific returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exposures(risk_exposures, ax=None):\n",
    "    rep = risk_exposures.stack().reset_index()\n",
    "    rep.columns = ['dt', 'factor', 'exposure']\n",
    "    sns.boxplot(x='exposure', y='factor', data=rep, orient='h', ax=ax, order=risk_exposures.columns[::-1])\n",
    "    \n",
    "plot_exposures(risk_exposures_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.cum_returns_final(perf_attribution).plot.barh()\n",
    "plt.xlabel('cumulative returns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_attribution.apply(ep.annual_volatility).plot.barh()\n",
    "plt.xlabel('Ann. volatility');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cum_returns_delay(factor, pricing, delay=range(5), ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    for d in delay:\n",
    "        portfolio_returns, _ = factor_portfolio_returns(alpha_df[\"combined_alpha\"], pricing, delay=d)\n",
    "        ep.cum_returns(portfolio_returns).plot(ax=ax, label=d)\n",
    "    ax.legend()\n",
    "    ax.set(ylabel='Cumulative returns', title='Cumulative returns if factor is delayed')\n",
    "    \n",
    "plot_cum_returns_delay(alpha_df[\"combined_alpha\"], pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor1_returns.plot()\n",
    "plt.ylabel('Returns')\n",
    "plt.legend(['Factor1']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pf.tears.create_perf_attrib_tear_sheet(factor1_returns,\n",
    "                                       positions=factor1_positions,\n",
    "                                       factor_returns=factor_returns,\n",
    "                                       factor_loadings=factor_loadings,      \n",
    "                                       pos_in_dollars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_factor1 = alpha_df['combined_alpha']\n",
    "sectors = alpha_df['Sector']\n",
    "prices = pricing\n",
    "periods = (1,3,5,10,21)\n",
    "\n",
    "factor_data1 = al.utils.get_clean_factor_and_forward_returns(factor=my_factor1,\n",
    "                                                            prices=prices,\n",
    "                                                            groupby=sectors,\n",
    "                                                            groupby_labels=MORNINGSTAR_SECTOR_CODES,\n",
    "                                                            periods=periods,\n",
    "                                                            quantiles = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al.tears.create_full_tear_sheet(factor_data1, by_group=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al.tears.create_information_tear_sheet(factor_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al.tears.create_event_returns_tear_sheet(factor_data=factor_data1,\n",
    "                                                        prices=prices,\n",
    "                                                        avgretplot=(5, 20),\n",
    "                                                        long_short=True,\n",
    "                                                        by_group=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factset.Fundamentals.bps_gr_af\n",
    "my_factor = factset.Fundamentals.earn_yld_af"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}